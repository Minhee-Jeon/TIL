# \0으로 끝나는 함수 구현하기(UTF-8)   
[0. 문자 인코딩 - ASCII / ANSI / EUC-KR / CP949 / UTF-8 / UNICODE](#문자-인코딩)        
[1. strlen](#strlen-구현하기)    
[2. strcpy](#strcpy-구현하기)    
[3. trcmp](#strcmp-구현하기)    
[4. strstr](#strstr-구현하기)    
[5. strtok](#strtok-구현하기)    

## 문자 인코딩    
인코딩은 정보의 형태나 형식을 변환하는 처리(방식)이다.    
즉 우리는 문자, 사진, 동영상 등 다양한 정보를 미리 정해둔 인코딩 기준으로 가공하는데, 여기에서는 문자 인코딩에 대해서만 정리한다.    
컴퓨터를 하다 아래와 같이 글자가 깨져서 알아보지 못한 경험은 누구나 있을 것이다.   
![8e83de4e-28da-4991-8052-abf2e56f2774](https://user-images.githubusercontent.com/58028527/87732888-102f0800-c809-11ea-8eea-3e829129e657.png)      
이렇게 깨지는 이유가 뭘까?    
바로 저장할 때의 인코딩 방식과 읽을 때의 인코딩 방식이 다르기 때문이다.   
만약 전세계 모든 사람들이 영어만 쓴다면 인코딩을 할 필요가 없다.    
하지만 우리가 쓸 자원은 한정되어 있고, 표현해야 할 글자의 가짓수가 무궁무진하기 때문에 더 효율적으로 글자를 표현할 방식을 정하다 보니 여러 인코딩 방식이 생겨나게 되었다.   
각각의 인코딩 방식에서 '이 글자는 이 코드로 정해두겠어!'라고 정해 둔 기준이 다르기 때문에, 입출력 시 인코딩이 다르면 똑같은 내용이라도 각기 다른 기준을 참조해서 해석하기 때문에 이렇게 의도하지 않았던 결과가 나오는 것이다!   
팀장님 피셜 개발자로써 꼭 알아야 할 한글 관련 문자 인코딩을 정리해 보았다.   
    
### 1. ASCII (American Standard Code for Information Interchange)   
![216CE84C52694FF020](https://user-images.githubusercontent.com/58028527/87650005-fbf8f580-c78b-11ea-8bbf-af283a56c290.png)   
**ASCII**는 7bit로 구성되어 있고 영어, 숫자, 특수문자 등 128개의 문자를 표현한다.   
영어만을 고려해 만들어졌기에 ASCII로 영어 외에 다른 언어는 표현할 수가 없다.   
이 단점을 보완해 다른 언어를 표현하기 위해 ANSI가 탄생했다.   
   
### 2. ANSI (American National Standard Institute)   
**ANSI**는 8bit로 구성되어 있고 256개의 문자를 표현할 수 있다.   
ANSI의 앞 7bit는 ASCII와 동일하고, 맨 뒤 1bit를 이용해서 타 언어의 문자를 표현한다.   
하지만 ASCII코드 외에 새로 추가된 128개의 문자로는 모든 언어의 문자를 표현하기엔 턱없이 부족하다!   
그래서 **CodePage** 라는 개념이 생겼는데, 각 언어별로 Code값을 주고, Code값에 따라 다른 문자열 페이지를 의미한다.   
때문에 영어 외 다른 언어를 사용할 경우 ANSI에서는 Code Page를 동일하게 맞춰야 한다.   
Code Page가 다르면 전혀 다른 기준으로 읽어들이기 때문에 의도하지 않은 결과가 나오기 때문이다.   
     
### 3. EUC-KR (Extended Unix Code-Korea)   
**EUC-KR**은 한글 지원을 위한 완성형 코드 조합이다.   
크기는 2바이트이며, 2바이트 내에서 표현할 수 있는 완성된 문자 수에는 한계가 있었다.    
ANSI를 한국에서 확장한 것이며, 외국에서는 높은 확률로 지원하지 않는다.   
   
### 4. CP949 (Code Page 949)   
**CP949**는 한글 지원을 위해 Windows 계열에서 나온 확장 완성형 코드 조합이다. (949는 한국의 페이지 번호를 의미한다.)    
EUC-KR의 표현의 한계를 개선해 만들어진 인코딩 형식이며, 기본적으로 EUC-KR과 호환이 된다.     
EUC-KR에서 표현할수 없는 문자는 초/중/종성 조합을 해 표현한다.   
MS사가 만들어서 MS949라고 불리기도 한다.   

### 5. UTF-8 (Universal coded character set + Transformation Format-8bit)     
ANSI는 다양한 언어를 지원하기 위해 CodePage 정보를 미리 알고 있어야 했다. 또 1바이트로 고정된 크기 때문에 최대 256자까지만 표현할 수 있었다.   
이런 ANSI의 단점을 보완하기 위해 만들어진 방식이 **UTF-8**이다.   
UTF-8은 표현할 문자에 따라 1바이트에서 4바이트까지 글자 크기를 변경해 사용하는 **멀티바이트**라는 개념을 이용하기 때문에 하나의 Character set에 최대 1,112,064자까지 표현이 가능하다.   
첫 128자(영어)는 ASCII 코드 값을 사용해 ANSI와 동일하며 크기는 1바이트다.   
대다수의 유럽 언어와 중동 지역 언어는 2바이트를 사용하며 한, 중, 일 등 동아시아권 언어는 3바이트 이상을 사용한다.   
1바이트 크기를 넘는 문자는 다음과 같은 비트 패턴으로 표시된다. 7비트 크기의 ASCII와 혼동되지 않도록 모든 바이트들의 최상위 비트에는 1이 온다.   
|코드 범위 (십육진법)|UTF-8 형식 (이진법)|설명|   
|---|---|---|   
|000000-00007F|```0xxxxxxx``` (1바이트)|ASCII와 동일한 범위|    
|000080-0007FF|```110xxxxx 10xxxxxx```(2바이트)|첫 바이트는 ```110``` 또는 ```1110```으로 시작하고, 나머지 바이트들은 ```10```으로 시작함|   
|000800-00FFFF|```1110xxxx 10xxxxxx 10xxxxxx```(3바이트)|위와 동일|    
|010000-10FFFF|```11110zzz 10zzxxxx 10xxxxxx 10xxxxxx```(4바이트)|UTF-16 서러게이트 쌍 영역 (ZZZZ = zzzzz - 1). UTF-8로 표시된 비트 패턴은 실제 코드 포인트와 동일하다.|   

### 6. UNICODE   
**UNICODE**는 인코딩 기준이 아니라 전 세계의 모든 문자를 컴퓨터에서 일관적으로 표현하도록 2바이트 숫자로 정해둔 기준이다.     
이런 유니코드를 표현하는 여러가지 인코딩 방식이 존재하는 것이다.   
[유니코드 목록: 한글](http://unicode.org/charts/PDF/UAC00.pdf)에서 한글의 기준 표를 확인할 수 있다.    
'가'의 유니코드 값은 'AC00'이다. AC00은 10진수로 44,032인데 8비트에 담기에는 너무 큰 수다.   
이 값을 1바이트(8비트) 단위로 쪼개어 저장하는 방법이 UTF-8이다.   
유니코드 값을 바로 사용하지 않고 UTF-8 인코딩 방식으로 사용하다 보니 UTF-8과 유니코드가 같은 것이라고 생각하기 쉽지만, 이런 차이점이 있으니 명심해 둘 것!   
     
      
## strlen 구현하기   
```c
#include <stdio.h>
#include <string.h>
int my_strlen(str);
int utf8_strlen(char*);

int main(void) {
  char *str = "가As0限かض";
  // printf("%d%d%d%d\n", (int)str[0], (int)str[1], (int)str[2], (int)str[3]);
  printf("%d\n", my_strlen(str));
}

int my_strlen(char * c){
  int szInput = 0;
  for(int i=0; c[i]; i++){
    szInput += 1;
  }
  return szInput;
}
```
기존에 구현했던 ```my_strlen()```을 실행해보면 내가 예상했던 값인 ```7```이 아닌 ```14```가 리턴된다.    
왜인가? ```my_strlen()```은 1바이트가 넘는 글자가 올 것이라는 예상을 하지 않고 구현된 **1바이트 글자만을 위한** 메소드이기 때문이다.   
그래서 위 UTF-8 : 멀티바이트 기준 표를 참고해서 ```utf8_strlen()```을 구현해보았다.   
   
   
```c
int utf8_strlen(char * c){
  int szInput = 0;
  for(int i=0; c[i]; i++){
    if(-64 <= c[i] && c[i] <= -33) i++; //2바이트 문자
    else if(-33 < c[i] && c[i]<= -17) i += 2; //3바이트 문자
    else if (-17 < c[i] && c[i] <= -9) i += 3; //4바이트 문자
    szInput += 1;
  }
  return szInput;
}
```   
UTF-8 기준 표를 보면 **2바이트** 짜리의 첫 바이트는 ```110```으로 시작하므로 ```c[i]```의 범위가 ```-64 ~ -33```일 것이고,   
**3바이트**짜리의 첫 바이트는 ```1110```으로 시작하므로 ```-32 ~ 17```,   
**4바이트**짜리의 첫 바이트는 ```11110```으로 시작하므로 ```-16 ~ -9```의 범위를 가질 것이라고 생각했다.   
하지만 이렇게 보면 어떻게 저 범위가 나오는지 직관적으로 이해되지 않는다.    
    
```c
int utf8_strlen(char * c){
  int szInput = 0;
  for(int i=0; c[i]; i++){
    if(c[i]>>6 == -1){  //바이트 맨 처음이 11인가? (예: 2~4바이트 / 아뇨: 1바이트)
      if(c[i]>>5 == -1){   //바이트 맨 처음이 111인가? (예: 3~4바이트 / 아뇨: 2바이트)
        if(c[i]>>4 == -1){   //바이트 맨 처음이 1111인가? (예: 4바이트 / 아뇨: 3바이트)
            i += 3;
        }
        else i += 2;
      }
      else i += 1;
    }
    szInput += 1;
  }
  return szInput;
}
```
이번에는 shift 연산자를 이용해서 몇 바이트인지를 걸러내보았지만, 
만약 unsigned라서 ```c[i]```를 오른쪽으로 shift 연산한 ```11111111```이 ```-1```이 되지 않으면 어떻게 되는지에 대한 해답은 내놓지 못했다.    
여기까지는 기존의 코드에 새로 생긴 경우의 수를 덕지덕지 붙여서 작성했다면, 이번에는 기존에 작성했던 코드를 이용해 재사용성을 높였다.   
    
```c
int one_char_size(char *s) {
  return 1;
}


int my_strlen(char * c){
  int szInput = 0;
  for(int i=0; c[i]; i+=one_char_size(c+i)){
    szInput += 1;
  }
  return szInput;
}
```    
```my_strlen()```은 1바이트만 염두에 두었기 때문에, 이렇게 고쳐쓸 수 있다.   
```for문```의 증감식을 따로 떼 핸들링하면 기존 함수를 더 이상 가공하지 않아도 된다.    
   
```c
int one_char_size_utf8(char *s) {
  if((s[0]&0x80) == 0) {
      return 1;
    }
    /*
    0xFF => 11111111
    c[i] => 11001010
    c[i]>>5 => 00000_11111110
    */
    else if((0x07 & (s[0]>>5)) == 0x6) {  //2바이트
      return 2;
    }
    else if((0x0F & (s[0]>>4)) == 0xE) {  //3바이트
      return 3;
    }
    else if((0x1F & (s[0]>>3)) == 0x1E) {  //4바이트
      return 4;
    }

  return 1;
}

int utf8_strlen(char * c){
  int szInput = 0;
  for(int i=0; c[i]; i+=one_char_size_utf8(c+i)){
    szInput += 1;
  }
  return szInput;
}
```
핸들링할 때 ```c[0]```이 ```110```/```1110```/```11110```로 시작하는지는 shift 연산 후 ```111```/```1111```/```11111```로 비트마스킹해서 추출해본 후 맞는 경우가 있을 때 해당 값으로 리턴하도록 구현했다.   
UTF-8 기준표는 아주 정교하게 고안되었기 때문에, ```0```/```110```/```1110```/```11110```/```10```으로 시작하는 각각의 경우의 수로 모든 문자를 구분할 수가 있다.    

#### reference   
[문자열 인코딩 개념 정리(ASCII/ANSI/EUC-KR/CP949/UTF-8/UNICODE)](https://onlywis.tistory.com/2)         
[문자 인코딩이랑?](https://vigli.tistory.com/52)    
